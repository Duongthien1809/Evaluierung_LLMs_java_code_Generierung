[
  {
    "prompt_technik": "CoT",
    "model_name": "gpt35",
    "total_evaluated": 50,
    "completion_evaluation": 0.62,
    "compilable_evaluation": 0.96,
    "code_bleu_average_score.bleu_score": 0.3910969543753493,
    "code_bleu_average_score.ngram_match_score": 0.23647618218791008,
    "code_bleu_average_score.weighted_ngram_match_score": 0.2980524702655662,
    "code_bleu_average_score.syntax_match_score": 0.5803462716211459,
    "code_bleu_average_score.dataflow_match_score": 0.44951289342677486,
    "codeBert_average_score.codeBert_average_precision": 0.8219289708137513,
    "codeBert_average_score.codeBert_average_recall": 0.8208032810688018,
    "codeBert_average_score.codeBert_average_f1": 0.8205655157566071
  },
  {
    "prompt_technik": "CoT",
    "model_name": "llama-guard-3-8b",
    "total_evaluated": 50,
    "completion_evaluation": 0.1,
    "compilable_evaluation": 0.62,
    "code_bleu_average_score.bleu_score": 0.38898029749412727,
    "code_bleu_average_score.ngram_match_score": 0.0040521010075612145,
    "code_bleu_average_score.weighted_ngram_match_score": 0.23686908896894793,
    "code_bleu_average_score.syntax_match_score": 0.315,
    "code_bleu_average_score.dataflow_match_score": 0.0,
    "codeBert_average_score.codeBert_average_precision": 0.7134123277664185,
    "codeBert_average_score.codeBert_average_recall": 0.4660496109724045,
    "codeBert_average_score.codeBert_average_f1": 0.5633004820346832
  },
  {
    "prompt_technik": "CoT",
    "model_name": "llama3-groq-70b-8192-tool-use-preview",
    "total_evaluated": 50,
    "completion_evaluation": 0.04,
    "compilable_evaluation": 0.46,
    "code_bleu_average_score.bleu_score": 0.3238560291205805,
    "code_bleu_average_score.ngram_match_score": 0.13102952670990844,
    "code_bleu_average_score.weighted_ngram_match_score": 0.1854470908045425,
    "code_bleu_average_score.syntax_match_score": 0.3717607037038866,
    "code_bleu_average_score.dataflow_match_score": 0.28718679526398444,
    "codeBert_average_score.codeBert_average_precision": 0.7709223246574402,
    "codeBert_average_score.codeBert_average_recall": 0.7354160809516906,
    "codeBert_average_score.codeBert_average_f1": 0.7507658314704895
  },
  {
    "prompt_technik": "CoT",
    "model_name": "gemma2-9b-it",
    "total_evaluated": 50,
    "completion_evaluation": 0.12,
    "compilable_evaluation": 0.82,
    "code_bleu_average_score.bleu_score": 0.40508696709564007,
    "code_bleu_average_score.ngram_match_score": 0.2549975746688062,
    "code_bleu_average_score.weighted_ngram_match_score": 0.326188024548848,
    "code_bleu_average_score.syntax_match_score": 0.5583656421222549,
    "code_bleu_average_score.dataflow_match_score": 0.4807966270426513,
    "codeBert_average_score.codeBert_average_precision": 0.83527095079422,
    "codeBert_average_score.codeBert_average_recall": 0.8362814354896545,
    "codeBert_average_score.codeBert_average_f1": 0.8346280813217163
  },
  {
    "prompt_technik": "CoT",
    "model_name": "gemma-7b-it",
    "total_evaluated": 50,
    "completion_evaluation": 0.14,
    "compilable_evaluation": 0.74,
    "code_bleu_average_score.bleu_score": 0.381512996729054,
    "code_bleu_average_score.ngram_match_score": 0.21696850699398673,
    "code_bleu_average_score.weighted_ngram_match_score": 0.3176606818098534,
    "code_bleu_average_score.syntax_match_score": 0.4729470634727605,
    "code_bleu_average_score.dataflow_match_score": 0.4184757346396154,
    "codeBert_average_score.codeBert_average_precision": 0.8274434304237366,
    "codeBert_average_score.codeBert_average_recall": 0.7643113106489181,
    "codeBert_average_score.codeBert_average_f1": 0.7929562103748321
  },
  {
    "prompt_technik": "CoT",
    "model_name": "llama3-70b-8192",
    "total_evaluated": 50,
    "completion_evaluation": 0.44,
    "compilable_evaluation": 0.9,
    "code_bleu_average_score.bleu_score": 0.41381414605900835,
    "code_bleu_average_score.ngram_match_score": 0.26491028281234236,
    "code_bleu_average_score.weighted_ngram_match_score": 0.34027150542678214,
    "code_bleu_average_score.syntax_match_score": 0.574160171434047,
    "code_bleu_average_score.dataflow_match_score": 0.4759146245628621,
    "codeBert_average_score.codeBert_average_precision": 0.8326133012771606,
    "codeBert_average_score.codeBert_average_recall": 0.7818541491031646,
    "codeBert_average_score.codeBert_average_f1": 0.8059125375747681
  },
  {
    "prompt_technik": "CoT",
    "model_name": "llama3-8b-8192",
    "total_evaluated": 50,
    "completion_evaluation": 0.26,
    "compilable_evaluation": 0.8,
    "code_bleu_average_score.bleu_score": 0.4041069970783848,
    "code_bleu_average_score.ngram_match_score": 0.2476733775102441,
    "code_bleu_average_score.weighted_ngram_match_score": 0.3387220620889474,
    "code_bleu_average_score.syntax_match_score": 0.5505918105901965,
    "code_bleu_average_score.dataflow_match_score": 0.4794407381241514,
    "codeBert_average_score.codeBert_average_precision": 0.8334388279914856,
    "codeBert_average_score.codeBert_average_recall": 0.7748924660682678,
    "codeBert_average_score.codeBert_average_f1": 0.8026908957958221
  },
  {
    "prompt_technik": "CoT",
    "model_name": "llama-3.1-70b-versatile",
    "total_evaluated": 50,
    "completion_evaluation": 0.22,
    "compilable_evaluation": 0.5,
    "code_bleu_average_score.bleu_score": 0.3897855507258755,
    "code_bleu_average_score.ngram_match_score": 0.23647785016085185,
    "code_bleu_average_score.weighted_ngram_match_score": 0.3103376761532441,
    "code_bleu_average_score.syntax_match_score": 0.5484839736964168,
    "code_bleu_average_score.dataflow_match_score": 0.46384270289298946,
    "codeBert_average_score.codeBert_average_precision": 0.821063380241394,
    "codeBert_average_score.codeBert_average_recall": 0.8054519808292389,
    "codeBert_average_score.codeBert_average_f1": 0.8115683960914611
  },
  {
    "prompt_technik": "CoT",
    "model_name": "llama3-groq-8b-8192-tool-use-preview",
    "total_evaluated": 50,
    "completion_evaluation": 0.06,
    "compilable_evaluation": 0.5,
    "code_bleu_average_score.bleu_score": 0.3891534325837147,
    "code_bleu_average_score.ngram_match_score": 0.2161611820744717,
    "code_bleu_average_score.weighted_ngram_match_score": 0.3238545415975242,
    "code_bleu_average_score.syntax_match_score": 0.5238487237087766,
    "code_bleu_average_score.dataflow_match_score": 0.4727492829540866,
    "codeBert_average_score.codeBert_average_precision": 0.8247695422172546,
    "codeBert_average_score.codeBert_average_recall": 0.7573998183012008,
    "codeBert_average_score.codeBert_average_f1": 0.788523086309433
  },
  {
    "prompt_technik": "CoT",
    "model_name": "mixtral-8x7b-32768",
    "total_evaluated": 50,
    "completion_evaluation": 0.28,
    "compilable_evaluation": 0.72,
    "code_bleu_average_score.bleu_score": 0.3878847359761485,
    "code_bleu_average_score.ngram_match_score": 0.2672606821667574,
    "code_bleu_average_score.weighted_ngram_match_score": 0.31377437770287814,
    "code_bleu_average_score.syntax_match_score": 0.5447534824565683,
    "code_bleu_average_score.dataflow_match_score": 0.42575040157839,
    "codeBert_average_score.codeBert_average_precision": 0.8388692033290863,
    "codeBert_average_score.codeBert_average_recall": 0.8502982234954835,
    "codeBert_average_score.codeBert_average_f1": 0.8436231327056884
  }
]
