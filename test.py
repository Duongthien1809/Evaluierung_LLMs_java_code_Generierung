# [
#         {"model_name": "gpt35", "model_type": "openai", "output_file": "output.jsonl",
#          "evaluation_method": "normal", "max_count": 50, "technik": "ToT"},
#         {"model_name": "gpt35", "model_type": "openai", "output_file": "output.jsonl",
#          "evaluation_method": "pass_at_k", "max_count": 50, "technik": "ToT"},
#
#         {"model_name": "gemma2-9b-it", "model_type": "llama", "output_file": "output.jsonl",
#          "evaluation_method": "normal", "max_count": 50, "technik": "ToT"},
#         {"model_name": "gemma2-9b-it", "model_type": "llama", "output_file": "output.jsonl",
#          "evaluation_method": "pass_at_k", "max_count": 50, "technik": "ToT"},
#
#         {"model_name": "gemma-7b-it", "model_type": "llama", "output_file": "output.jsonl",
#          "evaluation_method": "normal", "max_count": 50, "technik": "ToT"},
#         {"model_name": "gemma-7b-it", "model_type": "llama", "output_file": "output.jsonl",
#          "evaluation_method": "pass_at_k", "max_count": 50, "technik": "ToT"},
#
#         {"model_name": "llama-3.1-70b-versatile", "model_type": "llama", "output_file": "output.jsonl",
#          "evaluation_method": "pass_at_k", "max_count": 50, "technik": "ToT"},
#         {"model_name": "llama-3.1-70b-versatile", "model_type": "llama", "output_file": "output.jsonl",
#          "evaluation_method": "normal", "max_count": 50, "technik": "ToT"},
#
#         {"model_name": "llama-guard-3-8b", "model_type": "llama", "output_file": "output.jsonl",
#          "evaluation_method": "normal", "max_count": 50, "technik": "ToT"},
#         {"model_name": "llama-guard-3-8b", "model_type": "llama", "output_file": "output.jsonl",
#          "evaluation_method": "pass_at_k", "max_count": 50, "technik": "ToT"},
#
#         {"model_name": "llama3-70b-8192", "model_type": "llama", "output_file": "output.jsonl",
#          "evaluation_method": "normal", "max_count": 50, "technik": "ToT"},
#         {"model_name": "llama3-70b-8192", "model_type": "llama", "output_file": "output.jsonl",
#          "evaluation_method": "pass_at_k", "max_count": 50, "technik": "ToT"},
#
#         {"model_name": "llama3-8b-8192", "model_type": "llama", "output_file": "output.jsonl",
#          "evaluation_method": "normal", "max_count": 50, "technik": "ToT"},
#         {"model_name": "llama3-8b-8192", "model_type": "llama", "output_file": "output.jsonl",
#          "evaluation_method": "pass_at_k", "max_count": 50, "technik": "ToT"},
#
#         {"model_name": "llama3-groq-70b-8192-tool-use-preview", "model_type": "llama", "output_file": "output.jsonl",
#          "evaluation_method": "normal", "max_count": 50, "technik": "ToT"},
#         {"model_name": "llama3-groq-70b-8192-tool-use-preview", "model_type": "llama", "output_file": "output.jsonl",
#          "evaluation_method": "pass_at_k", "max_count": 50, "technik": "ToT"},
#
#         {"model_name": "llama3-groq-8b-8192-tool-use-preview", "model_type": "llama", "output_file": "output.jsonl",
#          "evaluation_method": "normal", "max_count": 50, "technik": "ToT"},
#         {"model_name": "llama3-groq-8b-8192-tool-use-preview", "model_type": "llama", "output_file": "output.jsonl",
#          "evaluation_method": "pass_at_k", "max_count": 50, "technik": "ToT"},
#
#         {"model_name": "mixtral-8x7b-32768", "model_type": "llama", "output_file": "output.jsonl",
#          "evaluation_method": "normal", "max_count": 50, "technik": "ToT"},
#         {"model_name": "mixtral-8x7b-32768", "model_type": "llama", "output_file": "output.jsonl",
#          "evaluation_method": "pass_at_k", "max_count": 50, "technik": "ToT"},
#         # Weitere Modelle hier hinzuf√ºgen
#     ]